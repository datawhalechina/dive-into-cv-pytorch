# 5.3 ConditionGANå®æˆ˜: å†æˆ˜æ‰‹å†™æ•°å­—ç”Ÿæˆ

åœ¨å®ç°ä¼ ç»Ÿçš„GANç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬æ˜¯ä¸æ˜¯ä¼šæœ‰è¿™æ ·çš„ä¸€ä¸ªå›°æƒ‘ï¼Œä¸ºä»€ä¹ˆæ¨¡å‹çš„è¾“å…¥æ˜¯ä»ä¸€ä¸ª**ç®€å•çš„åˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰**ä¸­**éšæœº**æŠ½æ ·å‡ºæ¥çš„ä¸€ä¸ªå¼ é‡ï¼Œèƒ½ä¸èƒ½åŠ ä¸Š**äººä¸ºæ§åˆ¶**çš„å› ç´ å‘¢ã€‚æ¯”å¦‚æˆ‘ä»¬æƒ³åœ¨ç”Ÿæˆæ–°å›¾åƒçš„æ—¶å€™ï¼Œè®©**Generator**èƒ½æŒ‰ç…§ç”¨æˆ·è¾“å…¥çš„æ–‡å­—æˆ–è€…å›¾ç‰‡è¦æ±‚ï¼Œäº§ç”Ÿå‡ºæŒ‡å®šéœ€æ±‚çš„å›¾ç‰‡ã€‚è€Œè¿™æ­£æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥æ‰€è¦ä»‹ç»çš„ï¼š**CGANï¼ˆæ¡ä»¶ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œï¼‰**ã€‚

## 5.3.1 CGANå®ç°çš„é—®é¢˜

ä¸‹é¢æˆ‘ä»¬æ¥ä¸¾ä¸€ä¸ªå¥½ç©çš„ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒä¾‹å­ï¼š	
å‡è®¾æˆ‘ä»¬åœ¨æ¨¡å‹çš„è¾“å…¥ä¸­ä¼ å…¥ä¸€æ®µæ–‡æœ¬ï¼š"red eyes"ï¼Œè®°ä½œ$label$ï¼Œé€šè¿‡**embeddingæŠ€æœ¯**å°†æ–‡æœ¬ç¼–ç æˆ**æ–‡æœ¬å¼ é‡**$c$ï¼Œè€Œ**Generator**æ‰€ä½œçš„å°±æ˜¯å°†**è¾“å…¥çš„æ–‡æœ¬å¼ é‡$c$**å’Œä¸€ä¸ªä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­**æŠ½æ ·å‡ºçš„å¼ é‡$z$**ä¸€èµ·åƒæ‰ï¼Œåå‡ºä¸€å¼ å›¾ç‰‡$x$ï¼Œå¯¹äº$x$ï¼Œå®ƒéœ€è¦æ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªè¦æ±‚ï¼š

- $y$æ˜¯**å°½å¯èƒ½çœŸå®**çš„åŠ¨æ¼«äººç‰©å›¾ç‰‡ã€‚
- $y$çš„ç‰¹å¾è¦**ç¬¦åˆè¾“å…¥çš„æ–‡æœ¬è¦æ±‚**ï¼Œæ¯”å¦‚"red eyes"ã€‚

ç”±äº$z$æ˜¯éšæœºæŠ½æ ·çš„ï¼Œå› æ­¤åŒä¸€ä¸ª$c$ï¼Œå¯ä»¥ç”Ÿæˆå¤šå¼ æ»¡è¶³è¦æ±‚çš„$x$

![CGAN](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/CGAN.png)

## 5.3.2 CGANçš„åŸç†

æˆ‘ä»¬çš„ç›®çš„æ˜¯ï¼Œæ—¢è¦è®©**è¾“å‡ºçš„å›¾ç‰‡çœŸå®**ï¼Œä¹Ÿè¦è®©è¾“å‡ºçš„å›¾ç‰‡**ç¬¦åˆæ¡ä»¶$c$çš„æè¿°**ã€‚

- å› æ­¤å¯¹äºç”Ÿæˆå™¨è€Œè¨€ï¼Œæ‰€ä½œçš„å°±æ˜¯å°†**è¾“å…¥çš„æ–‡æœ¬å¼ é‡**å’Œä¸€ä¸ªä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­**æŠ½æ ·å‡ºçš„å¼ é‡$z$**ä¸€èµ·åƒæ‰ï¼Œåå‡ºä¸€å¼ å›¾ç‰‡$x$ã€‚
- è€Œåˆ¤åˆ«å™¨è¾“å…¥ä¾¿è¢«æ”¹æˆäº†åŒæ—¶è¾“å…¥$x$å’Œ$c$ï¼Œè¾“å‡ºè¦åšä¸¤ä»¶äº‹æƒ…ï¼Œä¸€ä¸ªæ˜¯**åˆ¤æ–­ $x$ æ˜¯å¦æ˜¯çœŸå®å›¾ç‰‡**ï¼Œå¦ä¸€ä¸ªæ˜¯ **$x$ å’Œ $c$ æ˜¯å¦æ˜¯åŒ¹é…çš„**ã€‚

![CGANæ¶æ„](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/CGANæ¶æ„.png)

å› æ­¤å¯¹äºåˆ¤åˆ«å™¨å¯èƒ½ä¼šé¢ä¸´å‡ ç§å¯èƒ½

- ç”Ÿæˆçš„å›¾åƒçœŸå®ä¸”ç¬¦åˆæ¡ä»¶ Good
- ç”Ÿæˆçš„å›¾åƒçœŸå®ä½†ä¸ç¬¦åˆæ¡ä»¶ BAD
- ç”Ÿæˆçš„å›¾åƒè™šå‡ BAD

![pairå¯èƒ½æ€§](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/pairå¯èƒ½æ€§.png)

## 5.3.3 CGANçš„æ¶æ„

åœ¨GANè¿™ç§å®Œå…¨æ— ç›‘ç£çš„æ–¹å¼åŠ ä¸Šä¸€ä¸ªæ ‡ç­¾æˆ–ä¸€ç‚¹ç›‘ç£ä¿¡æ¯ï¼Œä½¿æ•´ä¸ªç½‘ç»œå°±å¯çœ‹æˆåŠç›‘ç£æ¨¡å‹ã€‚å…¶åŸºæœ¬æ¶æ„ä¸GANç±»ä¼¼ï¼Œåªè¦æ·»åŠ ä¸€ä¸ªæ¡ä»¶$c$å³å¯ï¼Œ$c$å°±æ˜¯åŠ å…¥çš„ç›‘ç£ä¿¡æ¯ï¼Œæ¯”å¦‚è¯´MNISTæ•°æ®é›†å¯ä»¥æä¾›æŸä¸ªæ•°å­—çš„æ ‡ç­¾ä¿¡æ¯ï¼Œäººè„¸ç”Ÿæˆå¯ä»¥æä¾›æ€§åˆ«ã€æ˜¯å¦å¾®ç¬‘ã€å¹´é¾„ç­‰ä¿¡æ¯ï¼Œå¸¦æŸä¸ªä¸»é¢˜çš„å›¾åƒç­‰æ ‡ç­¾ä¿¡æ¯ã€‚

ğŸ‰ğŸ‰ **åœ¨æ¥ä¸‹æ¥çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†ç»“åˆä»£ç ï¼Œæ·±å…¥çš„äº†è§£CGANçš„æ¨¡å‹æ¶æ„ï¼Œå®ç°ä¸€ä¸ªç®€å•çš„ç”ŸæˆæŒ‡å®šæ•°å­—çš„CGANç½‘ç»œã€‚**

### æ¨¡å‹è®­ç»ƒæµç¨‹

åœ¨æœ¬å°èŠ‚çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†æ¡ä»¶è®°ä½œç¬¦å·$cï¼ˆcondition)$ã€‚

> ç®—æ³•ï¼šCCGANçš„è®­ç»ƒè¿‡ç¨‹
>
> åœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼š
>
> - ä»æ•°æ®é›†é‡‡æ · m ä¸ªçœŸå®æ ‡ç­¾å’Œå¯¹åº”çš„çœŸå®å›¾ç‰‡çš„æ­£æ ·æœ¬ $\left\{\left(c^{1}, x^{1}\right),\left(c^{2}, x^{2}\right), \ldots,\left(c^{m}, x^{m}\right)\right\}$
> - ä»ä¸€ä¸ªåˆ†å¸ƒä¸­é‡‡æ · m ä¸ªå™ªéŸ³æ ·æœ¬ $\left\{z^{1}, z^{2}, \ldots, z^{m}\right\}$
> - é€šè¿‡ç”Ÿæˆç½‘ç»œï¼Œè¾“å…¥çœŸå®æ ‡ç­¾å’Œå™ªéŸ³æ ·æœ¬ï¼Œç”Ÿæˆå¯¹åº”æ ‡ç­¾çš„ m ä¸ªè™šå‡å›¾ç‰‡çš„æ•°æ® $\left\{\tilde{x}^{1}, \tilde{x}^{2}, \ldots, \tilde{x}^{m}\right\}, \tilde{x}^{i}=G\left(c^{i}, z^{i}\right)$
> - ä»æ•°æ®é›†é‡‡æ · m ä¸ªçœŸå®å›¾ç‰‡çš„æ ·æœ¬ $\left\{\hat{x}^{1}, \hat{x}^{2}, \ldots, \hat{x}^{m}\right\}$ï¼Œç”¨ä»¥ç»„åˆæˆçœŸå®å›¾ç‰‡ä½†ä¸ç¬¦åˆæ¡ä»¶çš„æ•°æ®å¯¹
> - æ›´æ–°åˆ¤åˆ«å™¨å‚æ•° $\theta_{d}$ ä»¥æœ€å¤§åŒ–ä¸‹å¼ï¼š
> $$
> \begin{array}{l}
> \tilde{V}=\frac{1}{m} \sum_{i=1}^{m} \log D\left(c^{i}, x^{i}\right) +\frac{1}{m} \sum_{i=1}^{m^{m}} \log \left(1-D\left(c^{i}, \tilde{x}^{i}\right)\right)+\frac{1}{m} \sum_{i=1}^{m} \log \left(1-D\left(c^{i}, \hat{x}^{i}\right)\right),\theta_{d} \leftarrow \theta_{d}+\eta \nabla \tilde{V}\left(\theta_{d}\right)
> \end{array}
> $$
>
> - ä»ä¸€ä¸ªåˆ†å¸ƒä¸­é‡‡æ · m ä¸ªå™ªéŸ³æ ·æœ¬ $\left\{z^{1}, z^{2}, \ldots, z^{m}\right\}$
> - ä»æ•°æ®é›†é‡‡æ · m ä¸ªæ–‡æœ¬æ¡ä»¶ $\left\{c^{1}, c^{2}, \ldots, c^{m}\right\}$
> - æ›´æ–°ç”Ÿæˆå™¨å™¨å‚æ•° $\theta_{g}$ ä»¥æœ€å¤§åŒ–ä¸‹å¼ï¼š
>
> $$
> \tilde{V}=\frac{1}{m} \sum_{i=1}^{m} \log \left(D\left(G\left(c^{i}, z^{i}\right)\right)\right), \theta_{g} \leftarrow \theta_{g}-\eta \nabla \tilde{V}\left(\theta_{g}\right)
> $$

å› ä¸º CGAN æ˜¯åŠç›‘ç£å­¦ä¹ ï¼Œé‡‡æ ·çš„æ¯ä¸€é¡¹éƒ½æ˜¯æ–‡å­—å’Œå›¾ç‰‡çš„ pairã€‚CGAN çš„æ ¸å¿ƒå°±æ˜¯åˆ¤æ–­ä»€ä¹ˆæ ·çš„ pair ç»™é«˜åˆ†ï¼Œä»€ä¹ˆæ ·çš„ pair ç»™ä½åˆ†ã€‚

### åˆ¤åˆ«å™¨

$$
\begin{array}{l}
\tilde{V}=\frac{1}{m} \sum_{i=1}^{m} \log D\left(c^{i}, x^{i}\right) \\
+\frac{1}{m} \sum_{i=1}^{m^{m}} \log \left(1-D\left(c^{i}, \tilde{x}^{i}\right)\right)+\frac{1}{m} \sum_{i=1}^{m} \log \left(1-D\left(c^{i}, \hat{x}^{i}\right)\right) \\
\end{array}
$$

ç¬¬ä¸€é¡¹æ˜¯æ­£ç¡®æ¡ä»¶ä¸çœŸå®å›¾ç‰‡çš„ pairï¼Œåº”è¯¥ç»™é«˜åˆ†ï¼›ç¬¬äºŒé¡¹æ˜¯æ­£ç¡®æ¡ä»¶ä¸ä»¿é€ å›¾ç‰‡çš„pairï¼Œåº”è¯¥ç»™ä½åˆ†ï¼ˆäºæ˜¯åŠ ä¸Šäº†â€œ1-â€ï¼‰ï¼›ç¬¬ä¸‰é¡¹æ˜¯é”™è¯¯æ¡ä»¶ä¸çœŸå®å›¾ç‰‡çš„ pairï¼Œä¹Ÿåº”è¯¥ç»™ä½åˆ†ã€‚å¯ä»¥æ˜æ˜¾çš„çœ‹å‡ºï¼ŒCGAN ä¸ GANs åœ¨åˆ¤åˆ«å™¨ä¸Šçš„ä¸åŒä¹‹å¤„å°±æ˜¯å¤šå‡ºäº†ç¬¬ä¸‰é¡¹ã€‚

``` python
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.label_emb = nn.Embedding(10,10) 
        #Embeddingç±»è¿”å›çš„æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º[æ¯å¥è¯ä¸ªæ•°ï¼Œ è¯ç»´åº¦]çš„çŸ©é˜µã€‚
        self.model = nn.Sequential(
            nn.Linear(794,1024),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Dropout(0.4),
            nn.Linear(1024,512),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Dropout(0.4),
            nn.Linear(512,256),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Dropout(0.4),
            nn.Linear(256,1),
            nn.Sigmoid()
        )
    def forward(self,x,labels):
    	# å°†å›¾ç‰‡reshapeä¸º(batch_size,784)çš„tensor
        x = x.view(x.size(0),784)
        # labelsæ˜¯ç”¨randintéšæœºåˆå§‹åŒ–åˆ°[0,9]çš„(batch_size,)çš„ä¸€ç»´tensorã€‚å½“ä½œæ¡ä»¶condition
        # æ¯ä¸€ä¸ªæ•°å­—åˆ†é…ä¸€ä¸ªé•¿åº¦ä¸º10çš„å‘é‡ã€‚æ‰€ä»¥c.shape=(batch_size,10)
        c = self.label_emb(labels)
        # x.shape=(batch_size,794)
        x = torch.cat([x,c],1)
        out = self.model(x) # out.shape=(batch_size,1)
        #å¯ä»¥åˆ é™¤æ•°ç»„å½¢çŠ¶ä¸­çš„å•ç»´åº¦æ¡ç›®ï¼Œå³æŠŠshapeä¸­ä¸º1çš„ç»´åº¦å»æ‰ï¼Œä½†æ˜¯å¯¹éå•ç»´çš„ç»´åº¦ä¸èµ·ä½œç”¨ã€‚
        return out.squeeze()
        
D = Discriminator().to(device)
```

### CGANåˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°

``` python
# å®šä¹‰åˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°äº¤å‰ç†µåŠä¼˜åŒ–å™¨
criterion = nn.BCELoss()

# å®šä¹‰åˆ¤æ–­å™¨å¯¹çœŸå›¾ç‰‡çš„æŸå¤±å‡½æ•°
real_validity = D(real_images,real_labels)
# æŸå¤±æ¯”è¾ƒï¼Œä¸1
d_loss_real = criterion(real_validity,torch.ones(batch_size).to(device))
# åˆ¤åˆ«å™¨ç”Ÿæˆçš„å€¼
real_score = real_validity

# å®šä¹‰åˆ¤åˆ«å™¨å¯¹å‡å›¾ç‰‡ï¼ˆå³ç”±æ½œåœ¨ç©ºé—´ç‚¹ç”Ÿæˆçš„å›¾ç‰‡ï¼‰çš„æŸå¤±å‡½æ•°
### åˆ›å»ºbatch_sizeè¡Œ100åˆ—çš„éšæœºæ•°çš„tensorï¼Œéšæœºå€¼çš„åˆ†å¸ƒå¼å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
z = torch.randn(batch_size,100).to(device)
### è¾“å…¥çš„æ¡ä»¶ï¼Œå³æƒ³è¦ç”Ÿæˆçš„æ•°å­—[0,9]ï¼Œå› æ­¤åˆ›å»ºå¤§å°ä¸ºbatch_sizeçš„ä¸€ç»´å¼ é‡ï¼Œå…¶ä¸­å–å€¼èŒƒå›´åœ¨[0,9]
conditions = torch.randint(0, 10, (batch_size,)).to(device)
### é€šè¿‡æ­£æ€åˆ†å¸ƒç”Ÿæˆçš„ç‰¹å¾æ•°ä¸º100çš„z,ä»¥åŠconditions,äº§ç”Ÿä¸€å¼ fake_images
fake_images = G(z, conditions)
# å®šä¹‰åˆ¤æ–­å™¨å¯¹å‡å›¾ç‰‡çš„æŸå¤±å‡½æ•°
fake_validity = D(fake_images, conditions)
# æŸå¤±æ¯”è¾ƒï¼Œä¸0
d_loss_fake = criterion(fake_validity, torch.zeros(batch_size).to(device))
fake_score = fake_images  # ç”Ÿæˆå™¨ç”Ÿæˆçš„å€¼

# total
d_loss = d_loss_fake + d_loss_real
```

### ç”Ÿæˆå™¨

$$
\tilde{V}=\frac{1}{m} \sum_{i=1}^{m} \log \left(D\left(G\left(c^{i}, z^{i}\right)\right)\right)
$$

ç”Ÿæˆå™¨çš„ç›®çš„å°±æ˜¯è®©åˆ¤åˆ«å™¨ç»™ä»¿é€ å›¾ç‰‡çš„å¾—åˆ†è¶Šé«˜è¶Šå¥½ï¼Œè¿™ä¸ä¼ ç»Ÿ GANs æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´çš„ï¼Œåªæ˜¯åœ¨è¾“å…¥ä¸Šå¤šäº†ä¸€ä¸ªå‚æ•° cã€‚

``` python
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        # æ¯ä¸€ä¸ªæ•°å­—åˆ†é…ä¸€ä¸ªé•¿åº¦ä¸º10çš„å‘é‡ï¼Œæ€»å…±åä¸ªæ•°å­—ï¼Œäº§ç”Ÿäº†10*10çš„tensor
        self.label_emb = nn.Embedding(10, 10)
        self.model = nn.Sequential(
            nn.Linear(110, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1024, 784),
            nn.Tanh()
        ) 
        
    def forward(self, z, labels):
    	# å®šä¹‰zæ˜¯ä¸ªä»randnå–æ ·å¾—åˆ°çš„shapeä¸º(batch_size,100)çš„äºŒç»´çš„tensor
        z = z.view(z.size(0), 100) 
        # labelsæ˜¯ç”¨randintéšæœºåˆå§‹åŒ–åˆ°[0,9]çš„(batch_size,)çš„ä¸€ç»´tensorã€‚å½“ä½œæ¡ä»¶condition
        # æ¯ä¸€ä¸ªæ•°å­—åˆ†é…ä¸€ä¸ªé•¿åº¦ä¸º10çš„å‘é‡ã€‚æ‰€ä»¥c.shape=(batch_size,10)
        c = self.label_emb(labels)
        # x.shape=(batch_size,110)
        x = torch.cat([z, c], 1)
        out = self.model(x)
        # å°†out reshapeä¸º(batch_size,28,28)çš„tensor
        return out.view(x.size(0), 28, 28)

G = Generator().to(device)
```

### CGANç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°

``` python
# å®šä¹‰ç”Ÿæˆå™¨å¯¹å‡å›¾ç‰‡çš„æŸå¤±å‡½æ•°ï¼Œè¿™é‡Œæˆ‘ä»¬è¦æ±‚
# åˆ¤åˆ«å™¨ç”Ÿæˆçš„å›¾ç‰‡è¶Šæ¥è¶ŠåƒçœŸå›¾ç‰‡ï¼Œæ•…æŸå¤±å‡½æ•°ä¸­
# çš„æ ‡ç­¾æ”¹ä¸ºçœŸå›¾ç‰‡çš„æ ‡ç­¾ï¼Œå³å¸Œæœ›ç”Ÿæˆçš„å‡å›¾ç‰‡ï¼Œ
# è¶Šæ¥è¶Šé è¿‘çœŸå›¾ç‰‡

### åˆ›å»ºbatch_sizeè¡Œ100åˆ—çš„éšæœºæ•°çš„tensorï¼Œéšæœºå€¼çš„åˆ†å¸ƒå¼å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
z = torch.randn(batch_size, 100).to(device)
### è¾“å…¥çš„æ¡ä»¶ï¼Œå³æƒ³è¦ç”Ÿæˆçš„æ•°å­—[0,9]ï¼Œå› æ­¤åˆ›å»ºå¤§å°ä¸ºbatch_sizeçš„ä¸€ç»´å¼ é‡ï¼Œå…¶ä¸­å–å€¼èŒƒå›´åœ¨[0,9]
conditions = torch.randint(0, 10, (batch_size,)).to(device)
### é€šè¿‡æ­£æ€åˆ†å¸ƒç”Ÿæˆçš„ç‰¹å¾æ•°ä¸º100çš„z,ä»¥åŠconditions,äº§ç”Ÿä¸€å¼ fake_images
fake_images = G(z, conditions)

# å®šä¹‰ç”Ÿæˆå™¨çš„æŸå¤±å‡½æ•°
validity = D(fake_images, fake_labels)
g_loss = criterion(validity, torch.ones(batch_size).to(device)) #æ ‡ç­¾ä¸º1
```

### ç›®æ ‡å‡½æ•°

$$
\min _{G} \max _{D} V(D, G)=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x} \mid \boldsymbol{c})]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z} \mid \boldsymbol{c})))] \tag{5}
$$

## 5.3.4 è®­ç»ƒæ¨¡å‹

``` python
# å®šä¹‰åˆ¤åˆ«å™¨çš„æŸå¤±å‡½æ•°äº¤å‰ç†µåŠä¼˜åŒ–å™¨
criterion = nn.BCELoss()
d_optimizer = torch.optim.Adam(D.parameters(),lr=0.0001)
g_optimizer = torch.optim.Adam(G.parameters(),lr=0.0001)

#Clampå‡½æ•°xé™åˆ¶åœ¨åŒºé—´[min, max]å†…
def denorm(x):
    out = (x+1)/2
    return out.clamp(0,1)

def reset_grad():
    d_optimizer.zero_grad()
    g_optimizer.zero_grad()

#å¼€å§‹è®­ç»ƒ
total_step = len(data_loader)

for epoch in range(num_epochs):
    for i,(images,labels) in enumerate(data_loader):
        step = epoch*len(data_loader)+i+1
        images = images.to(device)
        labels = labels.to(device)
        # å®šä¹‰å›¾åƒæ˜¯çœŸæˆ–å‡çš„æ ‡ç­¾
        real_labels = torch.ones(batch_size).to(device)  #çœŸæ ‡ç­¾å…¨æ˜¯1
        fake_labels = torch.randint(0,10,(batch_size,)).to(device) ##è¿”å›å‡åŒ€åˆ†å¸ƒçš„[0,10]ä¹‹é—´çš„æ•´æ•°éšæœºå€¼
        # ================================================================== #
        #                      è®­ç»ƒåˆ¤åˆ«å™¨                                    #
        # ================================================================== #

        # å®šä¹‰åˆ¤æ–­å™¨å¯¹çœŸå›¾ç‰‡çš„æŸå¤±å‡½æ•°
        real_validity = D(images,labels)
        d_loss_real = criterion(real_validity,real_labels)  #æŸå¤±æ¯”è¾ƒï¼Œä¸1
        real_score = real_validity   #åˆ¤åˆ«å™¨ç”Ÿæˆçš„å€¼
        # å®šä¹‰åˆ¤åˆ«å™¨å¯¹å‡å›¾ç‰‡ï¼ˆå³ç”±æ½œåœ¨ç©ºé—´ç‚¹ç”Ÿæˆçš„å›¾ç‰‡ï¼‰çš„æŸå¤±å‡½æ•°
        z = torch.randn(batch_size,100).to(device)
        #åˆ›å»ºbatch_sizeè¡Œ100åˆ—çš„éšæœºæ•°çš„tensorï¼Œéšæœºå€¼çš„åˆ†å¸ƒå¼å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
        fake_labels = torch.randint(0, 10, (batch_size,)).to(device)
        #åˆ›å»ºbatch_sizeè¡Œåˆ—ä¸æŒ‡å®šçš„éšæœºæ•´æ•°çš„tensorï¼Œéšæœºå€¼çš„åŒºé—´æ˜¯[low, high)[0,10]
        fake_images = G(z,fake_labels)
        fake_validity = D(fake_images,fake_labels)

        d_loss_fake = criterion(fake_validity, torch.zeros(batch_size).to(device)) #æŸå¤±æ¯”è¾ƒï¼Œä¸0
        fake_score = fake_images   #ç”Ÿæˆå™¨ç”Ÿæˆçš„å€¼
        d_loss= d_loss_fake + d_loss_real

        # å¯¹ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨çš„æ¢¯åº¦æ¸…é›¶
        reset_grad()
        d_loss.backward()
        d_optimizer.step()

        # ================================================================== #
        #                        è®­ç»ƒç”Ÿæˆå™¨                                  #
        # ================================================================== #

        # å®šä¹‰ç”Ÿæˆå™¨å¯¹å‡å›¾ç‰‡çš„æŸå¤±å‡½æ•°ï¼Œè¿™é‡Œæˆ‘ä»¬è¦æ±‚
        # åˆ¤åˆ«å™¨ç”Ÿæˆçš„å›¾ç‰‡è¶Šæ¥è¶ŠåƒçœŸå›¾ç‰‡ï¼Œæ•…æŸå¤±å‡½æ•°ä¸­
        # çš„æ ‡ç­¾æ”¹ä¸ºçœŸå›¾ç‰‡çš„æ ‡ç­¾ï¼Œå³å¸Œæœ›ç”Ÿæˆçš„å‡å›¾ç‰‡ï¼Œ
        # è¶Šæ¥è¶Šé è¿‘çœŸå›¾ç‰‡

        z = torch.randn(batch_size, 100).to(device)
        fake_images = G(z, fake_labels)
        validity = D(fake_images, fake_labels)
        g_loss = criterion(validity, torch.ones(batch_size).to(device)) #æ ‡ç­¾ä¸º1

        # å¯¹ç”Ÿæˆå™¨ã€åˆ¤åˆ«å™¨çš„æ¢¯åº¦æ¸…é›¶
        # è¿›è¡Œåå‘ä¼ æ’­åŠè¿è¡Œç”Ÿæˆå™¨çš„ä¼˜åŒ–å™¨
        reset_grad()
        g_loss.backward()
        g_optimizer.step()

        if (i + 1) % 200 == 0:
            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}'
                  .format(epoch, num_epochs, i + 1, total_step, d_loss.item(), g_loss.item(),
                          real_score.mean().item(), fake_score.mean().item() * (-1)))
    # ä¿å­˜çœŸå›¾ç‰‡
    if (epoch + 1) == 1:   #åªæ˜¯ä¿å­˜ä¸€å¼ 
        images = images.reshape(images.size(0), 1, 28, 28)
        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))

    # ä¿å­˜å‡å›¾ç‰‡
    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)
    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch + 1)))

# ä¿å­˜æ¨¡å‹
torch.save(G.state_dict(), 'G.ckpt')
torch.save(D.state_dict(), 'D.ckpt')
```

### å¯è§†åŒ–ç»“æœ

``` python
import matplotlib.pyplot as plt # plt ç”¨äºæ˜¾ç¤ºå›¾ç‰‡
import matplotlib.pyplot as plt # plt ç”¨äºæ˜¾ç¤ºå›¾ç‰‡
import matplotlib.image as mpimg # mpimg ç”¨äºè¯»å–å›¾ç‰‡

reconsPath = './cgan_samples/real_images.png'
Image = mpimg.imread(reconsPath)
plt.imshow(Image) # æ˜¾ç¤ºå›¾ç‰‡
plt.axis('off') # ä¸æ˜¾ç¤ºåæ ‡è½´
plt.show()

reconsPath = './cgan_samples/fake_images-50.png'
Image = mpimg.imread(reconsPath)
plt.imshow(Image) # æ˜¾ç¤ºå›¾ç‰‡
plt.axis('off') # ä¸æ˜¾ç¤ºåæ ‡è½´
plt.show()
```

![cgan_fake](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/cgan_fake.png)

### ç”Ÿæˆè‡ªå®šä¹‰å›¾ç‰‡

``` python
from torchvision.utils import make_grid
z = torch.randn(100, 100).to(device)
labels = torch.LongTensor([i for i in range(10) for _ in range(10)]).to(device)

images = G(z, labels).unsqueeze(1)
grid = make_grid(images, nrow=10, normalize=True)
#make_gridç”¨äºæŠŠå‡ ä¸ªå›¾åƒæŒ‰ç…§ç½‘æ ¼æ’åˆ—çš„æ–¹å¼ç»˜åˆ¶å‡ºæ¥
#æ¯è¡Œçš„å›¾ç‰‡æ•°é‡ä¸º10
#normalizeå¦‚æœä¸ºTrueï¼Œåˆ™æŠŠå›¾åƒçš„åƒç´ å€¼é€šè¿‡rangeæŒ‡å®šçš„æœ€å¤§å€¼å’Œæœ€å°å€¼å½’ä¸€åŒ–åˆ°0-1ã€‚
fig, ax = plt.subplots(figsize=(10,10))
#figä»£è¡¨ç»˜å›¾çª—å£(Figure)ï¼›axä»£è¡¨è¿™ä¸ªç»˜å›¾çª—å£ä¸Šçš„åæ ‡ç³»(axis)ï¼Œä¸€èˆ¬ä¼šç»§ç»­å¯¹axè¿›è¡Œæ“ä½œã€‚
#è¡¨ç¤ºfigure çš„å¤§å°ä¸ºå®½ã€é•¿ï¼ˆå•ä½ä¸ºinchï¼‰
ax.imshow(grid.permute(1, 2, 0).detach().cpu().numpy(), cmap='binary')
#grid.permute(1, 2, 0)å°†tensorçš„ç»´åº¦æ¢ä½ï¼ŒåŸæ¥çš„é¡ºåºæ˜¯ï¼ˆ0ï¼Œ1ï¼Œ2ï¼‰
#å½“ä½¿ç”¨detach()åˆ†ç¦»tensorä½†æ˜¯æ²¡æœ‰æ›´æ”¹è¿™ä¸ªtensoræ—¶ï¼Œå¹¶ä¸ä¼šå½±å“backward()
#æ˜¾ç¤ºè®¾ç½®ï¼Œä¸¤ç«¯å‘æ•£çš„è‰²å›¾ colormaps
ax.axis('off')
```

<img src="https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/CGAN_img.png" alt="CGAN_img" style="zoom:67%;" />

``` python
def generate_digit(generator, digit):
    z = torch.randn(1, 100).to(device)
    label = torch.LongTensor([digit]).to(device)
    img = generator(z, label).detach()
    img = 0.5 * img + 0.5  #è¿˜åŸå›¾åƒï¼Œåå½’ä¸€åŒ–
    return transforms.ToPILImage()(img)

generate_digit(G, 8)
```

![code](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/code.png)

## 5.3.5 CGANåˆ¤åˆ«å™¨æ¶æ„çš„è®¨è®º

![D_1](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/D_1.png)

å¤§éƒ¨åˆ†çš„ CGAN **åˆ¤åˆ«å™¨**éƒ½é‡‡ç”¨ä¸Šè¿°æ¶æ„ï¼Œä¸ºäº†æŠŠå›¾ç‰‡å’Œæ¡ä»¶ç»“åˆåœ¨ä¸€èµ·ï¼Œå¾€å¾€ä¼šæŠŠ$x$ä¸¢å…¥ä¸€ä¸ªç½‘ç»œäº§ç”Ÿä¸€ä¸ª embeddingï¼Œcondition ä¹Ÿä¸¢å…¥ä¸€ä¸ªç½‘ç»œäº§ç”Ÿä¸€ä¸ª embeddingï¼Œç„¶åæŠŠè¿™ä¸¤ä¸ª embedding æ‹¼åœ¨ä¸€èµ·ä¸¢å…¥ä¸€ä¸ªç½‘ç»œä¸­ï¼Œè¿™ä¸ªç½‘ç»œæ—¢è¦åˆ¤æ–­ç¬¬ä¸€ä¸ª embedding æ˜¯å¦çœŸå®ï¼ŒåŒæ—¶ä¹Ÿè¦åˆ¤æ–­ä¸¤ä¸ª embedding æ˜¯å¦é€»è¾‘ä¸ŠåŒ¹é…ï¼Œæœ€ç»ˆç»™å‡ºä¸€ä¸ªåˆ†æ•°ã€‚ä½†æ˜¯ä¹Ÿæœ‰ä¸€ç§CGAN é‡‡ç”¨äº†å¦å¤–ä¸€ç§æ¶æ„ã€‚

![D_2](https://raw.githubusercontent.com/datawhalechina/dive-into-cv-pytorch/master/markdown_imgs/chapter05/D_2.png)

**é¦–å…ˆæœ‰ä¸€ä¸ªç½‘ç»œå®ƒåªè´Ÿè´£åˆ¤æ–­è¾“å…¥ $x$ æ˜¯å¦æ˜¯ä¸€ä¸ªçœŸå®çš„å›¾ç‰‡**ï¼Œå¹¶ä¸”åŒæ—¶äº§ç”Ÿä¸€ä¸ªembeddingï¼Œä¸ $c$ ä¸€åŒä¼ ç»™ç¬¬äºŒä¸ªç½‘ç»œï¼›**ç„¶åç¬¬äºŒä¸ªç½‘ç»œåªéœ€åˆ¤æ–­ $x$ å’Œ $c$ æ˜¯å¦åŒ¹é…**ã€‚æœ€ç»ˆä¸¤ä¸ªç½‘ç»œçš„æ‰“åˆ†ä¾æ®æ¨¡å‹éœ€æ±‚è¿›è¡Œ**åŠ æƒç­›é€‰**å³å¯ã€‚  
**ä¼˜åŠ£åŠ¿å¯¹æ¯”ï¼š**ç¬¬äºŒç§æ¨¡å‹æœ‰ä¸€ä¸ªæ˜æ˜¾çš„å¥½å¤„å°±æ˜¯åˆ¤åˆ«å™¨èƒ½åŒºåˆ†å‡ºä¸ºä»€ä¹ˆè¿™æ ·çš„ pair ä¼šå¾—ä½åˆ†ï¼Œæ˜¯å› ä¸º $c$ ä¸åŒ¹é…è¿˜æ˜¯ $x$ ä¸å¤ŸçœŸå®ï¼›ç„¶è€Œå¯¹ç¬¬ä¸€ç§æ¨¡å‹å´ä¸çŸ¥é“å¾—åˆ†ä½çš„åŸå› æ˜¯ä»€ä¹ˆï¼Œè¿™ä¼šé€ æˆä¸€ç§æƒ…å†µå°±æ˜¯ç”Ÿæˆå™¨äº§ç”Ÿçš„å›¾ç‰‡å·²ç»è¶³å¤Ÿæ¸…æ™°äº†ï¼Œä½†æ˜¯å› ä¸ºä¸åŒ¹é… $c$ è€Œå¾—äº†ä½åˆ†ï¼Œè€Œç”Ÿæˆå™¨ä¸çŸ¥é“å¾—åˆ†ä½çš„åŸå› æ˜¯ä»€ä¹ˆï¼Œä¾ç„¶ä»¥ä¸ºæ˜¯äº§ç”Ÿçš„å›¾ç‰‡ä¸å¤Ÿæ¸…æ™°ï¼Œé‚£è¿™æ ·ç”Ÿæˆå™¨å°±æœ‰å¯èƒ½æœç€é”™è¯¯çš„æ–¹å‘è¿­ä»£ã€‚  
ä¸è¿‡ï¼Œç›®å‰ç¬¬ä¸€ç§æ¨¡å‹è¿˜æ˜¯è¢«å¹¿æ³›åº”ç”¨çš„ï¼Œå…¶å®äº‹å®ä¸ŠäºŒè€…çš„å·®å¼‚åœ¨å®é™…ä¸­ä¹Ÿä¸æ˜¯ç‰¹åˆ«æ˜æ˜¾ã€‚  

## 5.3.6 å°ç»“

åœ¨æœ¬èŠ‚å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†CGANæ¨¡å‹çš„åŸç†åŠæ¶æ„ï¼ŒåŒæ—¶åŸºäºCGANæ¨¡å‹å®Œæˆäº†æ‰‹å†™æ•°å­—æ¡ä»¶ç”Ÿæˆçš„æ¡ˆä¾‹ã€‚

å¯¹æ¯”ä¼ ç»Ÿçš„GANæ¨¡å‹ï¼ŒCGANæ¨¡å‹åœ¨è¾“å…¥éƒ¨åˆ†å¢åŠ äº†æ–‡æœ¬æ¡ä»¶$label$çš„è¾“å…¥ï¼Œä½†æ˜¯æ–‡æœ¬å­—ç¬¦ä¸²æ˜¯æ— æ³•ç›´æ¥å½“ä½œç”Ÿæˆå™¨ç½‘ç»œçš„è¾“å…¥ï¼Œéœ€è¦é€šè¿‡embeddingæŠ€æœ¯ç¼–ç ä¸ºæ–‡æœ¬å¼ é‡$c$ï¼Œæ‰èƒ½ç§°ä¸ºç”Ÿæˆå™¨ç½‘ç»œçš„è¾“å…¥ã€‚

å¯¹äºåˆ¤åˆ«å™¨ç½‘ç»œçš„æ¶æ„å­˜åœ¨ä¸¤ç§æ¨¡å‹ï¼Œä¸€ç§æ˜¯**åªç”¨ä¸€ä¸ªnetwork**ï¼ŒåŒæ—¶åƒå…¥å›¾ç‰‡å¼ é‡ $x$ å’Œæ–‡æœ¬å¼ é‡ $c$ ï¼Œè¿›è¡Œä¸¤ä¸ªä»»åŠ¡çš„åˆ¤æ–­ï¼›å¦ä¸€ç§ä½¿ç”¨äº†**ä¸¤ä¸ªnetwork**ï¼Œç¬¬ä¸€ä¸ªç½‘ç»œåªè´Ÿè´£åˆ¤æ–­è¾“å…¥ $x$ æ˜¯å¦æ˜¯ä¸€ä¸ªçœŸå®çš„å›¾ç‰‡ï¼Œå¹¶ä¸”åŒæ—¶äº§ç”Ÿä¸€ä¸ªembeddingï¼Œä¸ $c$ ä¸€åŒä¼ ç»™ç¬¬äºŒä¸ªç½‘ç»œï¼›ç„¶åç¬¬äºŒä¸ªç½‘ç»œåªéœ€åˆ¤æ–­ $x$ å’Œ $c$ æ˜¯å¦åŒ¹é…ã€‚æœ€ç»ˆä¸¤ä¸ªç½‘ç»œçš„æ‰“åˆ†ä¾æ®æ¨¡å‹éœ€æ±‚è¿›è¡Œ**åŠ æƒç­›é€‰**å³å¯ã€‚è™½ç„¶ç¬¬äºŒç§æ¨¡å‹èƒ½æ›´å¥½è§£é‡Šä»€ä¹ˆåŸå› å¯¼è‡´å¾—åˆ†ä½ï¼Œä½†æ˜¯äº‹å®ä¸ŠäºŒè€…çš„å·®å¼‚åœ¨å®é™…ä¸­ä¹Ÿä¸æ˜¯ç‰¹åˆ«æ˜æ˜¾ã€‚
